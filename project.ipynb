{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generalists and Specialists: How Language Barriers Affect Activity Diversity on Reddit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We study how the language of user/subreddit affects GS-score. To adhere the conventions from [Waller and Anderson 2019](https://dl.acm.org/doi/10.1145/3308558.3313729),  we will use \"community\" and \"subreddit\" interchangeably. Similarly, we will use \"user\" to mean a Redditor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from pandas import Series, DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will compute the necessary data for analysis. Namely, we will compute the following:\n",
    "\n",
    "- Compute GS-score for each user and community\n",
    "- Detect language for each comment\n",
    "- Based on comment language, compute language frequency for each user and community"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common Communities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have two source of data: community embeddings from https://github.com/CSSLab/social-dimensions and provided comments/submissions data on Reddit. Since our analysis combines the embeddings with the provided dataset, we will only consider the communities that are in both sources.\n",
    "\n",
    "To do so, we will first load the communities from the embedding, and filter the `text_comments.csv` dataset to only include communities that are in the embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['keto', 'AskReddit', 'funny', ..., 'barkour', 'wc2010_crests',\n",
       "       'PigJargon'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get communities from embedding\n",
    "import os\n",
    "SOCIAL_DIMENSIONS = '../social-dimensions'\n",
    "comms_embd = pd.read_csv(os.path.join(SOCIAL_DIMENSIONS, 'data/embedding-metadata.tsv'), sep='\\t', usecols=['community'])['community']\n",
    "comms_embd.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Language Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will detect the language of the comments in `text_comments.csv`. For language detection, we use [lingua](https://github.com/pemistahl/lingua-py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lingua import Language\n",
    "languages: dict[Language, str]  = { l: l.iso_code_639_3.name.lower() for l in Language.all() }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell will read `text_comments.csv`, exclude comments whose subreedit is not in the embedding, detect the language based on the comment's body, and finally put the results to `lang_comments.csv`.\n",
    "\n",
    "We only include comments whose language are detectable. Here are some examples of undetectable comments:\n",
    "\n",
    "- Removed comments (i.e. the body is `[removed]` or `[deleted]`)\n",
    "- Emoji only\n",
    "- URL only\n",
    "\n",
    "The result will be `lang_comments.csv` with the following columns\n",
    "\n",
    "<!--\n",
    "- `id`: unique id\n",
    "- `score`: score of comment based on upvote and downvotes\n",
    "- `created_utc`: datetime when the comment waw posted\n",
    "- `link_id`: id of submission to which this comment belongs\n",
    "For this part, we take a conservative approach to include a lot of columns. But in later analysis, the most important ones are `author`, `subreddit`, and `lang`.\n",
    "-->\n",
    "\n",
    "- `author`: username of comment\n",
    "- `subreddit`: name of the subreddit the comment was posted in\n",
    "- `lang`: language of comment, in ISO 639-3 code\n",
    "\n",
    "see [lang_comments.log](./lang_comments.log) for progross log."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from lingua import LanguageDetectorBuilder\n",
    "\n",
    "def detect(src_csv: str, dest_csv: str):\n",
    "    # remove existing file\n",
    "    if os.path.exists(dest_csv):\n",
    "        os.remove(dest_csv)\n",
    "    detector = LanguageDetectorBuilder.from_all_languages().build()\n",
    "    # placeholder for removed content/username\n",
    "    unwanted = [\"[removed]\", \"[deleted]\"]\n",
    "    # columns to keep\n",
    "    columns = ['author', 'subreddit', 'lang']\n",
    "    comms = set(comms_embd)\n",
    "    with pd.read_csv(src_csv, chunksize=10 ** 6, lineterminator='\\n') as reader:\n",
    "        for i, chunk in enumerate(reader):\n",
    "            # only keep comments from communities in embedding\n",
    "            chunk = chunk[chunk['subreddit'].isin(comms)]\n",
    "            chunk = chunk.replace(unwanted, None)\n",
    "            # the detector will return None if text is empty\n",
    "            chunk['body'] = chunk['body'].fillna('')\n",
    "            chunk['lang'] = detector.detect_languages_in_parallel_of(chunk['body'])\n",
    "            chunk = chunk[columns].dropna()\n",
    "            # map language to ISO 639-3 code\n",
    "            chunk['lang'] = chunk['lang'].map(languages)\n",
    "            print(f'Chunk {i:02d}: {len(chunk)} comments')\n",
    "            chunk.to_csv('lang_comments.csv', mode='a', index=False, header=(i == 0))\n",
    "detect('text_comments.csv', 'lang_comments.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will load the `lang_comments.csv` as precomputed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mega_trex</td>\n",
       "      <td>BeautyGuruChatter</td>\n",
       "      <td>eng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>divadream</td>\n",
       "      <td>BeautyGuruChatter</td>\n",
       "      <td>eng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ziegenkoennenfliegen</td>\n",
       "      <td>BeautyGuruChatter</td>\n",
       "      <td>eng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>meowrottenralph</td>\n",
       "      <td>BeautyGuruChatter</td>\n",
       "      <td>eng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>somethingelse19</td>\n",
       "      <td>BeautyGuruChatter</td>\n",
       "      <td>eng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29681125</th>\n",
       "      <td>AJTK</td>\n",
       "      <td>SquaredCircle</td>\n",
       "      <td>eng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29681126</th>\n",
       "      <td>imdelirious3</td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>eng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29681127</th>\n",
       "      <td>NocapNightingale</td>\n",
       "      <td>TheStrokes</td>\n",
       "      <td>eng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29681128</th>\n",
       "      <td>jag-engr</td>\n",
       "      <td>ChoosingBeggars</td>\n",
       "      <td>eng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29681129</th>\n",
       "      <td>Mercbeast</td>\n",
       "      <td>totalwar</td>\n",
       "      <td>eng</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29681130 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        author          subreddit lang\n",
       "0                    mega_trex  BeautyGuruChatter  eng\n",
       "1                    divadream  BeautyGuruChatter  eng\n",
       "2         Ziegenkoennenfliegen  BeautyGuruChatter  eng\n",
       "3              meowrottenralph  BeautyGuruChatter  eng\n",
       "4              somethingelse19  BeautyGuruChatter  eng\n",
       "...                        ...                ...  ...\n",
       "29681125                  AJTK      SquaredCircle  eng\n",
       "29681126          imdelirious3          AskReddit  eng\n",
       "29681127      NocapNightingale         TheStrokes  eng\n",
       "29681128              jag-engr    ChoosingBeggars  eng\n",
       "29681129             Mercbeast           totalwar  eng\n",
       "\n",
       "[29681130 rows x 3 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# use Category dtype to save memory\n",
    "lang_comments = pd.read_csv('lang_comments.csv', dtype={'lang':'category'})\n",
    "lang_comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we do not need the `text_submissions.csv` dataset. This is because our ultimate goal for this data wrangling section is to combine GS-scores with our current Reddit dataset. Since the [paper](http://csslab.cs.toronto.edu/gs/actdiv-www2019.pdf) defines GS-score based on contributions of a user, where contribution means *commenting* in a subreddit, it only makes sense to use only the comment dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GS Scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will compute the GS-scores for users and communities as per [Waller and Anderson 2019](https://dl.acm.org/doi/10.1145/3308558.3313729)\n",
    "\n",
    "First, we will filter the embedding since the only useful communities that are the ones that we have in our comments dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = pd.read_csv(os.path.join(SOCIAL_DIMENSIONS, 'data/embedding-vectors.tsv'), sep='\\t', header=None)\n",
    "embedding = embedding.set_index(comms_embd)\n",
    "# get common communites between embedding and comments\n",
    "embedding = embedding.loc[list(set(lang_comments['subreddit']) & set(comms_embd))]\n",
    "embedding.to_csv('embedding.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>140</th>\n",
       "      <th>141</th>\n",
       "      <th>142</th>\n",
       "      <th>143</th>\n",
       "      <th>144</th>\n",
       "      <th>145</th>\n",
       "      <th>146</th>\n",
       "      <th>147</th>\n",
       "      <th>148</th>\n",
       "      <th>149</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>community</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>whitesox</th>\n",
       "      <td>-0.210966</td>\n",
       "      <td>-0.033527</td>\n",
       "      <td>0.068185</td>\n",
       "      <td>-0.091237</td>\n",
       "      <td>0.077390</td>\n",
       "      <td>-0.023480</td>\n",
       "      <td>-0.634326</td>\n",
       "      <td>0.297105</td>\n",
       "      <td>0.078728</td>\n",
       "      <td>0.184559</td>\n",
       "      <td>...</td>\n",
       "      <td>0.327551</td>\n",
       "      <td>0.098173</td>\n",
       "      <td>-0.051080</td>\n",
       "      <td>-0.252188</td>\n",
       "      <td>0.573846</td>\n",
       "      <td>-0.695682</td>\n",
       "      <td>-0.049100</td>\n",
       "      <td>-0.315903</td>\n",
       "      <td>-0.350931</td>\n",
       "      <td>-0.308789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>needforspeed</th>\n",
       "      <td>0.117809</td>\n",
       "      <td>-0.045149</td>\n",
       "      <td>0.026157</td>\n",
       "      <td>-0.046551</td>\n",
       "      <td>0.037208</td>\n",
       "      <td>0.129973</td>\n",
       "      <td>0.128956</td>\n",
       "      <td>0.198981</td>\n",
       "      <td>0.053289</td>\n",
       "      <td>0.090528</td>\n",
       "      <td>...</td>\n",
       "      <td>0.189227</td>\n",
       "      <td>0.163141</td>\n",
       "      <td>0.120499</td>\n",
       "      <td>-0.109910</td>\n",
       "      <td>-0.002825</td>\n",
       "      <td>-0.295848</td>\n",
       "      <td>-0.182379</td>\n",
       "      <td>0.087979</td>\n",
       "      <td>-0.196882</td>\n",
       "      <td>0.123743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>singapore</th>\n",
       "      <td>-0.086955</td>\n",
       "      <td>0.042368</td>\n",
       "      <td>-0.458273</td>\n",
       "      <td>0.141884</td>\n",
       "      <td>0.145896</td>\n",
       "      <td>-0.136140</td>\n",
       "      <td>-0.209931</td>\n",
       "      <td>0.287035</td>\n",
       "      <td>0.125812</td>\n",
       "      <td>0.279292</td>\n",
       "      <td>...</td>\n",
       "      <td>0.329905</td>\n",
       "      <td>-0.232483</td>\n",
       "      <td>0.044648</td>\n",
       "      <td>-0.110947</td>\n",
       "      <td>-0.017498</td>\n",
       "      <td>-0.143914</td>\n",
       "      <td>-0.180745</td>\n",
       "      <td>0.101154</td>\n",
       "      <td>0.093565</td>\n",
       "      <td>-0.057554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>China</th>\n",
       "      <td>0.027609</td>\n",
       "      <td>0.003552</td>\n",
       "      <td>-0.191009</td>\n",
       "      <td>0.142138</td>\n",
       "      <td>0.106009</td>\n",
       "      <td>-0.014841</td>\n",
       "      <td>0.030333</td>\n",
       "      <td>0.723382</td>\n",
       "      <td>-0.396016</td>\n",
       "      <td>0.032850</td>\n",
       "      <td>...</td>\n",
       "      <td>0.400575</td>\n",
       "      <td>-0.182233</td>\n",
       "      <td>0.073708</td>\n",
       "      <td>-0.167503</td>\n",
       "      <td>0.188529</td>\n",
       "      <td>-0.123957</td>\n",
       "      <td>-0.230072</td>\n",
       "      <td>0.358343</td>\n",
       "      <td>-0.223186</td>\n",
       "      <td>0.108320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CanadaPolitics</th>\n",
       "      <td>-0.044821</td>\n",
       "      <td>0.020423</td>\n",
       "      <td>-0.162500</td>\n",
       "      <td>-0.283616</td>\n",
       "      <td>0.339133</td>\n",
       "      <td>0.006719</td>\n",
       "      <td>-0.260493</td>\n",
       "      <td>0.224549</td>\n",
       "      <td>0.112861</td>\n",
       "      <td>0.097335</td>\n",
       "      <td>...</td>\n",
       "      <td>0.445444</td>\n",
       "      <td>-0.065959</td>\n",
       "      <td>0.350684</td>\n",
       "      <td>0.080559</td>\n",
       "      <td>0.158537</td>\n",
       "      <td>-0.070104</td>\n",
       "      <td>-0.124536</td>\n",
       "      <td>0.446964</td>\n",
       "      <td>-0.072867</td>\n",
       "      <td>0.355092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>funhaus</th>\n",
       "      <td>0.184801</td>\n",
       "      <td>0.142184</td>\n",
       "      <td>0.005854</td>\n",
       "      <td>0.120801</td>\n",
       "      <td>0.051308</td>\n",
       "      <td>-0.104341</td>\n",
       "      <td>0.256501</td>\n",
       "      <td>0.008896</td>\n",
       "      <td>-0.119677</td>\n",
       "      <td>0.005178</td>\n",
       "      <td>...</td>\n",
       "      <td>0.317293</td>\n",
       "      <td>0.130474</td>\n",
       "      <td>0.381371</td>\n",
       "      <td>-0.579089</td>\n",
       "      <td>0.149820</td>\n",
       "      <td>-0.266531</td>\n",
       "      <td>0.411645</td>\n",
       "      <td>0.294616</td>\n",
       "      <td>-0.137921</td>\n",
       "      <td>0.067997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>speedrun</th>\n",
       "      <td>0.279569</td>\n",
       "      <td>0.074087</td>\n",
       "      <td>-0.155210</td>\n",
       "      <td>0.199809</td>\n",
       "      <td>0.063970</td>\n",
       "      <td>-0.084391</td>\n",
       "      <td>0.279174</td>\n",
       "      <td>0.255730</td>\n",
       "      <td>0.060109</td>\n",
       "      <td>0.241046</td>\n",
       "      <td>...</td>\n",
       "      <td>0.248152</td>\n",
       "      <td>0.248942</td>\n",
       "      <td>0.128581</td>\n",
       "      <td>-0.117363</td>\n",
       "      <td>0.102765</td>\n",
       "      <td>-0.205994</td>\n",
       "      <td>-0.158799</td>\n",
       "      <td>0.275427</td>\n",
       "      <td>-0.132525</td>\n",
       "      <td>0.180295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MakingaMurderer</th>\n",
       "      <td>0.088003</td>\n",
       "      <td>0.046263</td>\n",
       "      <td>-0.183474</td>\n",
       "      <td>0.021420</td>\n",
       "      <td>-0.204858</td>\n",
       "      <td>-0.159328</td>\n",
       "      <td>-0.149026</td>\n",
       "      <td>0.559824</td>\n",
       "      <td>-0.110523</td>\n",
       "      <td>0.390340</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001780</td>\n",
       "      <td>-0.114099</td>\n",
       "      <td>0.154348</td>\n",
       "      <td>-0.198905</td>\n",
       "      <td>0.286602</td>\n",
       "      <td>-0.059701</td>\n",
       "      <td>-0.017783</td>\n",
       "      <td>0.081613</td>\n",
       "      <td>-0.447207</td>\n",
       "      <td>0.356112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GRE</th>\n",
       "      <td>0.050482</td>\n",
       "      <td>-0.045961</td>\n",
       "      <td>-0.345226</td>\n",
       "      <td>0.161670</td>\n",
       "      <td>0.059878</td>\n",
       "      <td>0.016453</td>\n",
       "      <td>0.424253</td>\n",
       "      <td>0.580363</td>\n",
       "      <td>0.034056</td>\n",
       "      <td>-0.046038</td>\n",
       "      <td>...</td>\n",
       "      <td>0.138814</td>\n",
       "      <td>0.006454</td>\n",
       "      <td>-0.043733</td>\n",
       "      <td>-0.325318</td>\n",
       "      <td>0.116789</td>\n",
       "      <td>-0.192167</td>\n",
       "      <td>0.046609</td>\n",
       "      <td>0.336882</td>\n",
       "      <td>-0.176348</td>\n",
       "      <td>0.341897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EliteDangerous</th>\n",
       "      <td>0.221000</td>\n",
       "      <td>-0.071654</td>\n",
       "      <td>-0.333412</td>\n",
       "      <td>0.141201</td>\n",
       "      <td>0.126603</td>\n",
       "      <td>-0.089374</td>\n",
       "      <td>0.174736</td>\n",
       "      <td>0.155848</td>\n",
       "      <td>0.135351</td>\n",
       "      <td>0.226308</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.237711</td>\n",
       "      <td>0.269669</td>\n",
       "      <td>-0.179631</td>\n",
       "      <td>-0.088334</td>\n",
       "      <td>0.411584</td>\n",
       "      <td>-0.043240</td>\n",
       "      <td>-0.089249</td>\n",
       "      <td>-0.058792</td>\n",
       "      <td>-0.058682</td>\n",
       "      <td>-0.080694</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3183 rows Ã— 150 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        0         1         2         3         4         5  \\\n",
       "community                                                                     \n",
       "whitesox        -0.210966 -0.033527  0.068185 -0.091237  0.077390 -0.023480   \n",
       "needforspeed     0.117809 -0.045149  0.026157 -0.046551  0.037208  0.129973   \n",
       "singapore       -0.086955  0.042368 -0.458273  0.141884  0.145896 -0.136140   \n",
       "China            0.027609  0.003552 -0.191009  0.142138  0.106009 -0.014841   \n",
       "CanadaPolitics  -0.044821  0.020423 -0.162500 -0.283616  0.339133  0.006719   \n",
       "...                   ...       ...       ...       ...       ...       ...   \n",
       "funhaus          0.184801  0.142184  0.005854  0.120801  0.051308 -0.104341   \n",
       "speedrun         0.279569  0.074087 -0.155210  0.199809  0.063970 -0.084391   \n",
       "MakingaMurderer  0.088003  0.046263 -0.183474  0.021420 -0.204858 -0.159328   \n",
       "GRE              0.050482 -0.045961 -0.345226  0.161670  0.059878  0.016453   \n",
       "EliteDangerous   0.221000 -0.071654 -0.333412  0.141201  0.126603 -0.089374   \n",
       "\n",
       "                        6         7         8         9  ...       140  \\\n",
       "community                                                ...             \n",
       "whitesox        -0.634326  0.297105  0.078728  0.184559  ...  0.327551   \n",
       "needforspeed     0.128956  0.198981  0.053289  0.090528  ...  0.189227   \n",
       "singapore       -0.209931  0.287035  0.125812  0.279292  ...  0.329905   \n",
       "China            0.030333  0.723382 -0.396016  0.032850  ...  0.400575   \n",
       "CanadaPolitics  -0.260493  0.224549  0.112861  0.097335  ...  0.445444   \n",
       "...                   ...       ...       ...       ...  ...       ...   \n",
       "funhaus          0.256501  0.008896 -0.119677  0.005178  ...  0.317293   \n",
       "speedrun         0.279174  0.255730  0.060109  0.241046  ...  0.248152   \n",
       "MakingaMurderer -0.149026  0.559824 -0.110523  0.390340  ... -0.001780   \n",
       "GRE              0.424253  0.580363  0.034056 -0.046038  ...  0.138814   \n",
       "EliteDangerous   0.174736  0.155848  0.135351  0.226308  ... -0.237711   \n",
       "\n",
       "                      141       142       143       144       145       146  \\\n",
       "community                                                                     \n",
       "whitesox         0.098173 -0.051080 -0.252188  0.573846 -0.695682 -0.049100   \n",
       "needforspeed     0.163141  0.120499 -0.109910 -0.002825 -0.295848 -0.182379   \n",
       "singapore       -0.232483  0.044648 -0.110947 -0.017498 -0.143914 -0.180745   \n",
       "China           -0.182233  0.073708 -0.167503  0.188529 -0.123957 -0.230072   \n",
       "CanadaPolitics  -0.065959  0.350684  0.080559  0.158537 -0.070104 -0.124536   \n",
       "...                   ...       ...       ...       ...       ...       ...   \n",
       "funhaus          0.130474  0.381371 -0.579089  0.149820 -0.266531  0.411645   \n",
       "speedrun         0.248942  0.128581 -0.117363  0.102765 -0.205994 -0.158799   \n",
       "MakingaMurderer -0.114099  0.154348 -0.198905  0.286602 -0.059701 -0.017783   \n",
       "GRE              0.006454 -0.043733 -0.325318  0.116789 -0.192167  0.046609   \n",
       "EliteDangerous   0.269669 -0.179631 -0.088334  0.411584 -0.043240 -0.089249   \n",
       "\n",
       "                      147       148       149  \n",
       "community                                      \n",
       "whitesox        -0.315903 -0.350931 -0.308789  \n",
       "needforspeed     0.087979 -0.196882  0.123743  \n",
       "singapore        0.101154  0.093565 -0.057554  \n",
       "China            0.358343 -0.223186  0.108320  \n",
       "CanadaPolitics   0.446964 -0.072867  0.355092  \n",
       "...                   ...       ...       ...  \n",
       "funhaus          0.294616 -0.137921  0.067997  \n",
       "speedrun         0.275427 -0.132525  0.180295  \n",
       "MakingaMurderer  0.081613 -0.447207  0.356112  \n",
       "GRE              0.336882 -0.176348  0.341897  \n",
       "EliteDangerous  -0.058792 -0.058682 -0.080694  \n",
       "\n",
       "[3183 rows x 150 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding = pd.read_csv('embedding.csv', index_col=['community'])\n",
    "embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the community embeddings and user contributions, we can calculate the GS-score of a user. According to the paper (3.1), the GS-score of a user $u_i$ is defined as\n",
    "\n",
    "$$\n",
    "GS(u_i)=\\frac1J\\sum_jw_j\\frac{\\vec c_j\\cdot\\vec\\mu_i}{||\\mu_i||}\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "- $\\vec c_j$ is the embedding vector of community $c_j$\n",
    "- $w_j$ is the number of contribitions/comments that user $u_i$ makes in community $c_j$\n",
    "- $\\vec\\mu_i$ is the *center of mass* of user $u_i$, that is, $\\vec\\mu_i=\\sum_jw_j\\vec c_j$\n",
    "\n",
    "In other words, the GS-score is the average cosine similarity between $u_i$'s communities and $u_i$'s center of mass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "total = lang_comments['author'].nunique()\n",
    "i = 0\n",
    "\n",
    "def gs_user(group: DataFrame):\n",
    "    \"\"\"\n",
    "    returns GS-score of a user, given that group is grouped by author\n",
    "    \"\"\"\n",
    "    comms = group['subreddit']\n",
    "    w: Series = comms.value_counts()\n",
    "    c = embedding.loc[comms.unique()]\n",
    "    Î¼ = c.mul(w, axis=0).sum().values\n",
    "    global i\n",
    "    i += 1\n",
    "    if i % 1000 == 0:\n",
    "        print(f'{i}/{total}: {i/total:.2%}')\n",
    "    return cosine_similarity(c, Î¼.reshape(1, -1)).mean()\n",
    "\n",
    "uscores = lang_comments[['author','subreddit']].groupby('author').apply(gs_user)\n",
    "uscores.name = 'uscore'\n",
    "uscores.to_csv('uscores.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "author\n",
       "------------------GL    1.000000\n",
       "------------------O     1.000000\n",
       "------------------f     0.740005\n",
       "--------------Emkay     0.686527\n",
       "-------------0          1.000000\n",
       "                          ...   \n",
       "zzzzzzzzzzzzccccccgg    0.687017\n",
       "zzzzzzzzzzzzvzzzzvzz    0.813356\n",
       "zzzzzzzzzzzzzs          1.000000\n",
       "zzzzzzzzzzzzzzzzspaf    0.674736\n",
       "zzzzzzzzzzzzzzzzzu      1.000000\n",
       "Name: uscore, Length: 6911138, dtype: float64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uscores = pd.read_csv('uscores.csv', index_col='author')['uscore']\n",
    "uscores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With user scores, we can then calculate the community score (3.2). The GS-score of a community $c_i$ is the weight average over its users."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "GS(c_i)=\\frac1N\\sum_jw_jGS(u_j)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = lang_comments['subreddit'].nunique()\n",
    "i = 0\n",
    "\n",
    "def gs_comm(data: DataFrame):\n",
    "    \"\"\"\n",
    "    return GS-score of a community, given that data is grouped by subreddit\n",
    "    \"\"\"\n",
    "    w = data.groupby('author').apply('count')['subreddit']\n",
    "    gs = uscores.loc[data['author'].unique()]\n",
    "    global i\n",
    "    i += 1\n",
    "    if i % 100 == 0:\n",
    "        print(f'{i}/{total}: {i/total:.2%}')\n",
    "    return np.average(gs, weights=w)\n",
    "\n",
    "cscores = lang_comments[['author','subreddit']].groupby('subreddit').apply(gs_comm)\n",
    "cscores.name = 'cscore'\n",
    "cscores.to_csv('cscores.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "subreddit\n",
       "1200isplenty    0.806710\n",
       "13ReasonsWhy    0.802825\n",
       "13or30          0.719325\n",
       "195             0.741930\n",
       "2007scape       0.821024\n",
       "                  ...   \n",
       "youtubers       0.838359\n",
       "yugioh          0.819044\n",
       "zelda           0.767611\n",
       "zen             0.812143\n",
       "zerocarb        0.771824\n",
       "Name: cscore, Length: 3183, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cscores = pd.read_csv('cscores.csv', index_col='subreddit')['cscore']\n",
    "cscores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Language Frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we will calculate the frequency for each user and community."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_langs = lang_comments.pivot_table(index='author', columns='lang', fill_value=0, aggfunc=len).astype(np.float32)\n",
    "user_langs = user_langs.div(user_langs.sum(axis=1), axis=0)\n",
    "user_langs.to_csv('user_langs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>afr</th>\n",
       "      <th>ara</th>\n",
       "      <th>aze</th>\n",
       "      <th>bel</th>\n",
       "      <th>bos</th>\n",
       "      <th>bul</th>\n",
       "      <th>cat</th>\n",
       "      <th>ces</th>\n",
       "      <th>cym</th>\n",
       "      <th>dan</th>\n",
       "      <th>...</th>\n",
       "      <th>hin</th>\n",
       "      <th>kat</th>\n",
       "      <th>urd</th>\n",
       "      <th>ben</th>\n",
       "      <th>guj</th>\n",
       "      <th>pan</th>\n",
       "      <th>hye</th>\n",
       "      <th>tam</th>\n",
       "      <th>mar</th>\n",
       "      <th>tel</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>author</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>------------------GL</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>------------------O</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>------------------f</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>--------------Emkay</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-------------0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zzzzzzzzzzzzccccccgg</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zzzzzzzzzzzzvzzzzvzz</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zzzzzzzzzzzzzs</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zzzzzzzzzzzzzzzzspaf</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zzzzzzzzzzzzzzzzzu</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6911138 rows Ã— 75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      afr  ara  aze  bel  bos  bul  cat  ces  cym  dan  ...  \\\n",
       "author                                                                  ...   \n",
       "------------------GL  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "------------------O   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "------------------f   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "--------------Emkay   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "-------------0        0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "...                   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "zzzzzzzzzzzzccccccgg  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "zzzzzzzzzzzzvzzzzvzz  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "zzzzzzzzzzzzzs        0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "zzzzzzzzzzzzzzzzspaf  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "zzzzzzzzzzzzzzzzzu    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "\n",
       "                      hin  kat  urd  ben  guj  pan  hye  tam  mar  tel  \n",
       "author                                                                  \n",
       "------------------GL  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "------------------O   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "------------------f   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "--------------Emkay   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "-------------0        0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "...                   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  \n",
       "zzzzzzzzzzzzccccccgg  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "zzzzzzzzzzzzvzzzzvzz  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "zzzzzzzzzzzzzs        0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "zzzzzzzzzzzzzzzzspaf  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "zzzzzzzzzzzzzzzzzu    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[6911138 rows x 75 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_langs = pd.read_csv('user_langs.csv', index_col='author')\n",
    "user_langs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comm_langs = lang_comments[['subreddit', 'lang']].pivot_table(index='subreddit', columns='lang', fill_value=0, aggfunc=len).astype(np.float32)\n",
    "comm_langs = comm_langs.div(comm_langs.sum(axis=1), axis=0)\n",
    "comm_langs.to_csv('comm_langs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>afr</th>\n",
       "      <th>ara</th>\n",
       "      <th>aze</th>\n",
       "      <th>bel</th>\n",
       "      <th>bos</th>\n",
       "      <th>bul</th>\n",
       "      <th>cat</th>\n",
       "      <th>ces</th>\n",
       "      <th>cym</th>\n",
       "      <th>dan</th>\n",
       "      <th>...</th>\n",
       "      <th>hin</th>\n",
       "      <th>kat</th>\n",
       "      <th>urd</th>\n",
       "      <th>ben</th>\n",
       "      <th>guj</th>\n",
       "      <th>pan</th>\n",
       "      <th>hye</th>\n",
       "      <th>tam</th>\n",
       "      <th>mar</th>\n",
       "      <th>tel</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subreddit</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1200isplenty</th>\n",
       "      <td>0.002959</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000423</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001479</td>\n",
       "      <td>0.000634</td>\n",
       "      <td>0.001479</td>\n",
       "      <td>0.000634</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13ReasonsWhy</th>\n",
       "      <td>0.001788</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001788</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002384</td>\n",
       "      <td>0.000596</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13or30</th>\n",
       "      <td>0.004069</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000904</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000904</td>\n",
       "      <td>0.002260</td>\n",
       "      <td>0.009946</td>\n",
       "      <td>0.004069</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>0.009174</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000917</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002752</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002752</td>\n",
       "      <td>0.000917</td>\n",
       "      <td>0.016514</td>\n",
       "      <td>0.008257</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007scape</th>\n",
       "      <td>0.002756</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000479</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001757</td>\n",
       "      <td>0.000519</td>\n",
       "      <td>0.005312</td>\n",
       "      <td>0.002336</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>youtubers</th>\n",
       "      <td>0.000422</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000845</td>\n",
       "      <td>0.000422</td>\n",
       "      <td>0.000422</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000845</td>\n",
       "      <td>0.002111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yugioh</th>\n",
       "      <td>0.001566</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000522</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001268</td>\n",
       "      <td>0.000373</td>\n",
       "      <td>0.003356</td>\n",
       "      <td>0.002088</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zelda</th>\n",
       "      <td>0.003019</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000483</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000604</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000725</td>\n",
       "      <td>0.000604</td>\n",
       "      <td>0.004106</td>\n",
       "      <td>0.002053</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zen</th>\n",
       "      <td>0.003234</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000606</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001011</td>\n",
       "      <td>0.000809</td>\n",
       "      <td>0.003436</td>\n",
       "      <td>0.002021</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zerocarb</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000613</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000613</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002454</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3183 rows Ã— 75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   afr      ara       aze  bel       bos       bul       cat  \\\n",
       "subreddit                                                                      \n",
       "1200isplenty  0.002959  0.00000  0.000000  0.0  0.000423  0.000000  0.001479   \n",
       "13ReasonsWhy  0.001788  0.00000  0.000000  0.0  0.001788  0.000000  0.000000   \n",
       "13or30        0.004069  0.00000  0.000000  0.0  0.000904  0.000000  0.000904   \n",
       "195           0.009174  0.00000  0.000917  0.0  0.002752  0.000000  0.002752   \n",
       "2007scape     0.002756  0.00002  0.000200  0.0  0.000479  0.000000  0.001757   \n",
       "...                ...      ...       ...  ...       ...       ...       ...   \n",
       "youtubers     0.000422  0.00000  0.000000  0.0  0.000845  0.000422  0.000422   \n",
       "yugioh        0.001566  0.00000  0.000149  0.0  0.000522  0.000000  0.001268   \n",
       "zelda         0.003019  0.00000  0.000483  0.0  0.000604  0.000000  0.000725   \n",
       "zen           0.003234  0.00000  0.000000  0.0  0.000606  0.000000  0.001011   \n",
       "zerocarb      0.000000  0.00000  0.000000  0.0  0.000613  0.000000  0.000613   \n",
       "\n",
       "                   ces       cym       dan  ...  hin  kat  urd  ben  guj  pan  \\\n",
       "subreddit                                   ...                                 \n",
       "1200isplenty  0.000634  0.001479  0.000634  ...  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "13ReasonsWhy  0.000000  0.002384  0.000596  ...  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "13or30        0.002260  0.009946  0.004069  ...  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "195           0.000917  0.016514  0.008257  ...  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "2007scape     0.000519  0.005312  0.002336  ...  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "...                ...       ...       ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "youtubers     0.000000  0.000845  0.002111  ...  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "yugioh        0.000373  0.003356  0.002088  ...  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "zelda         0.000604  0.004106  0.002053  ...  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "zen           0.000809  0.003436  0.002021  ...  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "zerocarb      0.000000  0.002454  0.000000  ...  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "              hye  tam  mar  tel  \n",
       "subreddit                         \n",
       "1200isplenty  0.0  0.0  0.0  0.0  \n",
       "13ReasonsWhy  0.0  0.0  0.0  0.0  \n",
       "13or30        0.0  0.0  0.0  0.0  \n",
       "195           0.0  0.0  0.0  0.0  \n",
       "2007scape     0.0  0.0  0.0  0.0  \n",
       "...           ...  ...  ...  ...  \n",
       "youtubers     0.0  0.0  0.0  0.0  \n",
       "yugioh        0.0  0.0  0.0  0.0  \n",
       "zelda         0.0  0.0  0.0  0.0  \n",
       "zen           0.0  0.0  0.0  0.0  \n",
       "zerocarb      0.0  0.0  0.0  0.0  \n",
       "\n",
       "[3183 rows x 75 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comm_langs = pd.read_csv('comm_langs.csv', index_col='subreddit')\n",
    "comm_langs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is all the data wrangling we need. For the analysis, see [index.ipynb](./index.ipynb)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
